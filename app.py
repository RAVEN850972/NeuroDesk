from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import FileResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, Field
from typing import Optional, Dict, Any, List
import uvicorn
import os
import time
from pathlib import Path

# –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –≤–µ—Ä—Å–∏—é –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
# –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –≤—ã –±—ã –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–ª–∏ —Å–≤–æ–∏ –º–æ–¥—É–ª–∏
import json
import asyncio
from openai import OpenAI

app = FastAPI(
    title="NeuroDesk Hybrid API",
    description="–ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –≥–∏–±—Ä–∏–¥–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π (–≥—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π + OpenAI)",
    version="2.0.0"
)

# –ü–æ–¥–∫–ª—é—á–∞–µ–º —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∞–π–ª—ã
static_dir = Path("static")
if static_dir.exists():
    app.mount("/static", StaticFiles(directory="static"), name="static")

# –ü—Ä–æ—Å—Ç–∞—è –∏–º–∏—Ç–∞—Ü–∏—è NeuroDesk –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
class SimpleNeuroDesk:
    def __init__(self, openai_api_key=None):
        self.openai_client = None
        if openai_api_key:
            try:
                self.openai_client = OpenAI(api_key=openai_api_key)
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ OpenAI: {e}")
        
        self.knowledge_graph = {}  # –ü—Ä–æ—Å—Ç–æ–π –≥—Ä–∞—Ñ –∑–Ω–∞–Ω–∏–π
        self.stats = {
            "total_queries": 0,
            "graph_responses": 0,
            "openai_fallbacks": 0,
            "learning_sessions": 0
        }
        
    def ask(self, prompt: str, domain: str = "general", feedback: int = None) -> Dict[str, Any]:
        """–ü—Ä–æ—Å—Ç–∞—è –∏–º–∏—Ç–∞—Ü–∏—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞."""
        self.stats["total_queries"] += 1
        start_time = time.time()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –æ—Ç–≤–µ—Ç –≤ "–≥—Ä–∞—Ñ–µ –∑–Ω–∞–Ω–∏–π"
        graph_answer = self.knowledge_graph.get(prompt.lower())
        
        if graph_answer:
            # –û—Ç–≤–µ—Ç –∏–∑ –≥—Ä–∞—Ñ–∞
            self.stats["graph_responses"] += 1
            return {
                "answer": graph_answer,
                "success": True,
                "confidence": 0.8,
                "source": "graph",
                "processing_time": time.time() - start_time,
                "components_used": ["semgraph", "memory"],
                "explanation": ["–û—Ç–≤–µ—Ç –Ω–∞–π–¥–µ–Ω –≤ –≥—Ä–∞—Ñ–µ –∑–Ω–∞–Ω–∏–π"],
                "warnings": []
            }
        else:
            # Fallback –Ω–∞ OpenAI
            if self.openai_client:
                try:
                    response = self.openai_client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[
                            {"role": "system", "content": f"–¢—ã —É–º–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –≤ –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏: {domain}"},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=0.7,
                        max_tokens=500
                    )
                    
                    answer = response.choices[0].message.content.strip()
                    
                    # "–û–±—É—á–∞–µ–º" –≥—Ä–∞—Ñ (—Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç)
                    self.knowledge_graph[prompt.lower()] = answer
                    self.stats["openai_fallbacks"] += 1
                    self.stats["learning_sessions"] += 1
                    
                    return {
                        "answer": answer,
                        "success": True,
                        "confidence": 0.9,
                        "source": "openai_fallback",
                        "processing_time": time.time() - start_time,
                        "components_used": ["openai_api"],
                        "explanation": ["–û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω –æ—Ç OpenAI", "–ì—Ä–∞—Ñ –æ–±—É—á–µ–Ω –Ω–∞ —ç—Ç–æ–º –æ—Ç–≤–µ—Ç–µ"],
                        "warnings": [],
                        "learned_from_openai": True,
                        "tokens_used": response.usage.total_tokens if response.usage else None
                    }
                    
                except Exception as e:
                    return {
                        "answer": f"‚ùå –û—à–∏–±–∫–∞ OpenAI: {str(e)}",
                        "success": False,
                        "confidence": 0.0,
                        "source": "error",
                        "processing_time": time.time() - start_time,
                        "error": str(e)
                    }
            else:
                return {
                    "answer": "‚ùå OpenAI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ –≥—Ä–∞—Ñ–µ –∑–Ω–∞–Ω–∏–π",
                    "success": False,
                    "confidence": 0.0,
                    "source": "error",
                    "processing_time": time.time() - start_time,
                    "error": "OpenAI API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"
                }
    
    def learn(self, text: str, domain: str = "general") -> Dict[str, Any]:
        """–ü—Ä–æ—Å—Ç–æ–µ –æ–±—É—á–µ–Ω–∏–µ."""
        # –ü—Ä–æ—Å—Ç–∞—è –∏–º–∏—Ç–∞—Ü–∏—è: —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—Å—Ç –∫–∞–∫ –µ—Å—Ç—å
        key = f"learned_{len(self.knowledge_graph)}"
        self.knowledge_graph[key] = text
        self.stats["learning_sessions"] += 1
        
        return {
            "success": True,
            "message": "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ –∏–∑—É—á–µ–Ω–∞",
            "nodes_added": 1,
            "edges_added": 0,
            "processing_time": 0.1
        }
    
    def get_system_stats(self) -> Dict[str, Any]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã."""
        total = self.stats["total_queries"]
        return {
            "user_id": "demo_user",
            "session_id": "demo_session",
            "components_status": {"graph": "available", "openai": "available" if self.openai_client else "unavailable"},
            "pipeline_stats": {
                **self.stats,
                "graph_success_rate": self.stats["graph_responses"] / max(1, total),
            },
            "learning_quality": {"total_learned": len(self.knowledge_graph)},
            "tuner_stats": {"best_score": 0.8, "mutation_rate": 0.1}
        }
    
    def get_learning_quality_report(self) -> Dict[str, Any]:
        """–û—Ç—á–µ—Ç –æ –∫–∞—á–µ—Å—Ç–≤–µ –æ–±—É—á–µ–Ω–∏—è."""
        return {
            "total_learned": len(self.knowledge_graph),
            "recent_stats": [],
            "averages": {
                "avg_nodes_added": 1.0,
                "avg_edges_added": 0.0,
                "avg_relevance_score": 0.7
            }
        }

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
desk = None

def get_desk():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ NeuroDesk —Å –ª–µ–Ω–∏–≤–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π."""
    global desk
    if desk is None:
        openai_key = "API ONPEN AI KEY"
        desk = SimpleNeuroDesk(openai_api_key=openai_key)
    return desk

# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class AskRequest(BaseModel):
    prompt: str = Field(..., min_length=1, max_length=2000, description="–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    feedback: Optional[int] = Field(None, ge=-1, le=1, description="–û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å (-1, 0, 1)")
    domain: Optional[str] = Field(None, max_length=50, description="–ü—Ä–µ–¥–º–µ—Ç–Ω–∞—è –æ–±–ª–∞—Å—Ç—å")
    explanation_level: str = Field("detailed", pattern="^(basic|detailed|debug)$")

class AskResponse(BaseModel):
    answer: str
    success: bool
    confidence: Optional[float] = None
    source: str  # "graph", "openai_fallback", "error"
    processing_time: Optional[float] = None
    explanation: Optional[List[str]] = None
    warnings: Optional[List[str]] = None
    learned_from_openai: Optional[bool] = None
    tokens_used: Optional[int] = None

class LearnRequest(BaseModel):
    text: str = Field(..., min_length=10, max_length=5000, description="–¢–µ–∫—Å—Ç –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è")
    domain: str = Field("general", max_length=50, description="–ü—Ä–µ–¥–º–µ—Ç–Ω–∞—è –æ–±–ª–∞—Å—Ç—å")
    context: Optional[Dict[str, Any]] = Field(None, description="–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç")

class LearnResponse(BaseModel):
    success: bool
    message: str
    nodes_added: int = 0
    edges_added: int = 0
    processing_time: Optional[float] = None
    error: Optional[str] = None

# API endpoints
@app.post("/ask", response_model=AskResponse, 
          summary="–ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—É",
          description="–û—Å–Ω–æ–≤–Ω–æ–π endpoint –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –≥–∏–±—Ä–∏–¥–Ω—ã–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º")
async def ask(request: AskRequest):
    try:
        neurodesk = get_desk()
        
        result = neurodesk.ask(
            prompt=request.prompt,
            domain=request.domain or "general",
            feedback=request.feedback
        )
        
        return AskResponse(**result)
    
    except Exception as e:
        return AskResponse(
            answer=f"‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}",
            success=False,
            source="error"
        )

@app.post("/learn", response_model=LearnResponse,
          summary="–û–±—É—á–∏—Ç—å —Å–∏—Å—Ç–µ–º—É",
          description="–Ø–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–º —Ç–µ–∫—Å—Ç–µ")
async def learn(request: LearnRequest):
    try:
        neurodesk = get_desk()
        
        result = neurodesk.learn(
            text=request.text,
            domain=request.domain
        )
        
        return LearnResponse(**result)
    
    except Exception as e:
        return LearnResponse(
            success=False,
            message=f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {str(e)}",
            error=str(e)
        )

@app.get("/stats",
         summary="–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã",
         description="–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã")
async def get_stats():
    try:
        neurodesk = get_desk()
        stats = neurodesk.get_system_stats()
        return stats
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {str(e)}")

@app.get("/learning_quality",
         summary="–ö–∞—á–µ—Å—Ç–≤–æ –æ–±—É—á–µ–Ω–∏—è",
         description="–û—Ç—á–µ—Ç –æ –∫–∞—á–µ—Å—Ç–≤–µ –æ–±—É—á–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã")
async def get_learning_quality(max_entries: int = 10):
    try:
        neurodesk = get_desk()
        report = neurodesk.get_learning_quality_report()
        return report
    
    except Exception as e:
        return {"error": str(e)}

@app.get("/health",
         summary="–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è",
         description="–ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã")
async def health_check():
    try:
        neurodesk = get_desk()
        stats = neurodesk.get_system_stats()
        
        return {
            "status": "healthy",
            "openai_available": neurodesk.openai_client is not None,
            "total_queries": stats["pipeline_stats"]["total_queries"],
            "graph_success_rate": stats["pipeline_stats"]["graph_success_rate"]
        }
    
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e)
        }

# –ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
@app.get("/", 
         summary="–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞",
         description="–í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞")
async def root():
    static_index = Path("static/index.html")
    if static_index.exists():
        return FileResponse("static/index.html")
    else:
        return JSONResponse({
            "message": "NeuroDesk Hybrid API - –î–µ–º–æ –≤–µ—Ä—Å–∏—è",
            "version": "2.0.0",
            "docs": "/docs",
            "health": "/health",
            "status": "running",
            "endpoints": {
                "ask": "POST /ask - –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å",
                "learn": "POST /learn - –û–±—É—á–∏—Ç—å —Å–∏—Å—Ç–µ–º—É",
                "stats": "GET /stats - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞",
                "health": "GET /health - –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è"
            },
            "demo_available": True
        })

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–æ–±—ã—Ç–∏–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
@app.on_event("startup")
async def startup_event():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ."""
    print("üöÄ –ó–∞–ø—É—Å–∫ NeuroDesk Hybrid API (Demo –≤–µ—Ä—Å–∏—è)...")
    
    print("‚úÖ OpenAI API –∫–ª—é—á –Ω–∞–π–¥–µ–Ω")
    
    print("‚úÖ NeuroDesk –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
    print("üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: http://localhost:9000/docs")
    print("üåê –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å: http://localhost:9000")

@app.on_event("shutdown")
async def shutdown_event():
    """–û—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏."""
    print("üõë –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã NeuroDesk...")
    print("üëã –°–µ—Ä–≤–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

# Middleware –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
@app.middleware("http")
async def log_requests(request: Request, call_next):
    """Middleware –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤."""
    start_time = time.time()
    
    response = await call_next(request)
    
    process_time = time.time() - start_time
    
    # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ API –≤—ã–∑–æ–≤—ã
    if request.url.path.startswith("/api") or request.url.path in ["/ask", "/learn", "/stats"]:
        print(f"üìù {request.method} {request.url.path} - {response.status_code} - {process_time:.3f}s")
    
    return response

if __name__ == "__main__":
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∑–∞–ø—É—Å–∫–∞
    host = os.getenv("HOST", "0.0.0.0")
    port = int(os.getenv("PORT", 9000))
    debug = os.getenv("DEBUG", "false").lower() == "true"
    
    print(f"üåê –ó–∞–ø—É—Å–∫ –Ω–∞ http://{host}:{port}")
    print(f"üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: http://{host}:{port}/docs")
    
    uvicorn.run(
        "working_app:app", 
        host=host, 
        port=port, 
        reload=debug,
        log_level="info" if not debug else "debug"
    )
